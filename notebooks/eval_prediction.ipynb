{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from au2v.config import ModelConfig, TrainerConfig\n",
    "from au2v.dataset_manager import load_dataset_manager\n",
    "from au2v.trainer import PyTorchTrainer\n",
    "from au2v.model import load_model, PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(\n",
    "    model: PyTorchModel,\n",
    "    num_item: int,\n",
    "    test_dataset: list[tuple[int, list[int], list[int]]],\n",
    "    top_k: list[int],\n",
    ") -> dict[str, float]:\n",
    "    hit_counts = {k: 0 for k in top_k}\n",
    "    for seq_index, context_items, target_indices in tqdm.tqdm(test_dataset):\n",
    "        rec_list = model.output_rec_lists(\n",
    "            seq_index=torch.LongTensor([seq_index]),\n",
    "            item_indices=torch.LongTensor([context_items]),\n",
    "            cand_item_indices=torch.arange(num_item),\n",
    "            k=max(top_k),\n",
    "        )\n",
    "        for k in top_k:\n",
    "            hit_counts[k] += len(set(target_indices) & set(rec_list[0][:k]))\n",
    "\n",
    "    total_rec = len(test_dataset)\n",
    "    results = {\n",
    "        f\"Accuracy@{k}\": hit_count / total_rec / k\n",
    "        for k, hit_count in hit_counts.items()\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_configs = [\n",
    "    # {\n",
    "    #     \"name\": \"User2Vec (d=16)\",\n",
    "    #     \"model_name\": \"doc2vec\",\n",
    "    #     \"d_model\": 16,\n",
    "    #     \"epochs\": 3,\n",
    "    #     \"use_weight_tying\": True,\n",
    "    #     \"use_attention\": True,\n",
    "    #     \"use_meta\": True,\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"User2Vec (d=32)\",\n",
    "    #     \"model_name\": \"doc2vec\",\n",
    "    #     \"d_model\": 32,\n",
    "    #     \"epochs\": 3,\n",
    "    #     \"use_weight_tying\": True,\n",
    "    #     \"use_attention\": True,\n",
    "    #     \"use_meta\": True,\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"User2Vec (d=64)\",\n",
    "    #     \"model_name\": \"doc2vec\",\n",
    "    #     \"d_model\": 64,\n",
    "    #     \"epochs\": 10,\n",
    "    #     \"use_weight_tying\": True,\n",
    "    #     \"use_attention\": True,\n",
    "    #     \"use_meta\": True,\n",
    "    # },\n",
    "    {\n",
    "        \"name\": \"AU2V (d=16)\",\n",
    "        \"model_name\": \"attentive\",\n",
    "        \"d_model\": 16,\n",
    "        \"epochs\": 5,\n",
    "        \"use_weight_tying\": True,\n",
    "        \"use_attention\": True,\n",
    "        \"use_meta\": True,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"AU2V (d=32)\",\n",
    "        \"model_name\": \"attentive\",\n",
    "        \"d_model\": 32,\n",
    "        \"epochs\": 5,\n",
    "        \"use_weight_tying\": True,\n",
    "        \"use_attention\": True,\n",
    "        \"use_meta\": True,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"AU2V (d=64)\",\n",
    "        \"model_name\": \"attentive\",\n",
    "        \"d_model\": 64,\n",
    "        \"epochs\": 5,\n",
    "        \"use_weight_tying\": True,\n",
    "        \"use_attention\": True,\n",
    "        \"use_meta\": True,\n",
    "    },\n",
    "    # {\n",
    "    #     \"name\": \"AU2V (wo weight-tying)\",\n",
    "    #     \"model_name\": \"attentive\",\n",
    "    #     \"d_model\": 64,\n",
    "    #     \"epochs\": 3,\n",
    "    #     \"use_weight_tying\": False,\n",
    "    #     \"use_attention\": True,\n",
    "    #     \"use_meta\": True,\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"AU2V (wo attention)\",\n",
    "    #     \"model_name\": \"attentive\",\n",
    "    #     \"d_model\": 64,\n",
    "    #     \"epochs\": 3,\n",
    "    #     \"use_weight_tying\": True,\n",
    "    #     \"use_attention\": False,\n",
    "    #     \"use_meta\": True,\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"AU2V (wo meta)\",\n",
    "    #     \"model_name\": \"attentive\",\n",
    "    #     \"d_model\": 64,\n",
    "    #     \"epochs\": 3,\n",
    "    #     \"use_weight_tying\": True,\n",
    "    #     \"use_attention\": True,\n",
    "    #     \"use_meta\": False,\n",
    "    # },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for run_config in run_configs:\n",
    "    results[run_config[\"name\"]] = {\"accuracy\": []}\n",
    "    model_config = ModelConfig(\n",
    "        weight_decay=1e-8,\n",
    "        max_embedding_norm=5,\n",
    "        d_model=run_config[\"d_model\"],\n",
    "        lr=5e-5,\n",
    "        use_attention=run_config[\"use_attention\"],\n",
    "        use_meta=run_config[\"use_meta\"],\n",
    "        use_weight_tying=run_config[\"use_weight_tying\"],\n",
    "    )\n",
    "    trainer_config = TrainerConfig(\n",
    "        dataset_name=\"movielens\",\n",
    "        model_name=run_config[\"model_name\"],\n",
    "        load_dataset=False,\n",
    "        save_dataset=False,\n",
    "        load_model=False,\n",
    "        ignore_saved_model=True,\n",
    "        epochs=run_config[\"epochs\"],\n",
    "    )\n",
    "\n",
    "    print(model_config)\n",
    "    print(trainer_config)\n",
    "\n",
    "    dataset_manager = load_dataset_manager(\n",
    "        dataset_name=trainer_config.dataset_name,\n",
    "        dataset_dir=trainer_config.dataset_dir,\n",
    "        data_dir=\"../data/\",\n",
    "        load_dataset=trainer_config.load_dataset,\n",
    "        save_dataset=trainer_config.save_dataset,\n",
    "        window_size=model_config.window_size,\n",
    "    )\n",
    "    print(\n",
    "        \"train:\",\n",
    "        len(dataset_manager.train_dataset),\n",
    "        \"valid:\",\n",
    "        len(dataset_manager.valid_dataset),\n",
    "    )\n",
    "    model = load_model(\n",
    "        dataset_manager=dataset_manager,\n",
    "        trainer_config=trainer_config,\n",
    "        model_config=model_config,\n",
    "    )\n",
    "    trainer = PyTorchTrainer(\n",
    "        model=model,\n",
    "        dataset_manager=dataset_manager,\n",
    "        trainer_config=trainer_config,\n",
    "        model_config=model_config,\n",
    "    )\n",
    "\n",
    "    def on_epoch_end(epoch: int):\n",
    "        result = calc_accuracy(\n",
    "            model=model,\n",
    "            num_item=dataset_manager.num_item,\n",
    "            test_dataset=dataset_manager.test_datasets[\"test\"],\n",
    "            top_k=[10, 20, 30, 40, 50],\n",
    "        )\n",
    "        print(epoch, result)\n",
    "        results[run_config[\"name\"]][\"accuracy\"].append(result)\n",
    "        torch.save(model, f\"cache/model/movielens-2/{run_config['name']}-{epoch}.pt\")\n",
    "\n",
    "    losses = trainer.fit(on_epoch_end=on_epoch_end)\n",
    "    results[run_config[\"name\"]][\"loss\"] = losses\n",
    "\n",
    "    with open(\"result.json\", \"w\") as f:\n",
    "        json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = list(range(10, 51, 10))\n",
    "data = {}\n",
    "for method, result in results.items():\n",
    "    data[method] = []\n",
    "    for k in top_k:\n",
    "        a = max(map(lambda r: r[f\"Accuracy@{k}\"], result[\"accuracy\"]))\n",
    "        data[method].append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data).T\n",
    "df.columns = [f\"Accuracy@{k}\" for k in top_k]\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
