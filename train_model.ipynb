{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyst import Analyst\n",
    "from config import ModelConfig, TrainerConfig\n",
    "from dataset import load_dataset_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = TrainerConfig(\n",
    "    dataset_name=\"toydata\", epochs=1, ignore_saved_model=True, load_model=False, batch_size=64\n",
    ")\n",
    "model_config = ModelConfig(d_model=128, lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainerConfig(model_name='attentive2', dataset_name='toydata', epochs=1, batch_size=64, verbose=False, ignore_saved_model=True, load_model=False, save_model=True, load_dataset=True, save_dataset=True, cache_dir='cache/', dataset_dir='cache/dataset/')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelConfig(d_model=128, max_embedding_norm=None, window_size=8, negative_sample_size=5, lr=0.005, use_learnable_embedding=True, dropout=0.1, add_seq_embedding=False, add_positional_encoding=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cached dataset_manager from: cache/dataset/toydata.pickle\n"
     ]
    }
   ],
   "source": [
    "dataset_manager = load_dataset_manager(\n",
    "    dataset_name=trainer_config.dataset_name,\n",
    "    dataset_dir=trainer_config.dataset_dir,\n",
    "    load_dataset=trainer_config.load_dataset,\n",
    "    save_dataset=trainer_config.save_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst = Analyst(\n",
    "    dataset_manager=dataset_manager,\n",
    "    trainer_config=trainer_config,\n",
    "    model_config=model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 213/7313 [00:03<01:45, 67.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mセル7 を /Users/tatsuyaishii/dev/my-doc2vec/train_model.ipynb\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tatsuyaishii/dev/my-doc2vec/train_model.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m analyst\u001b[39m.\u001b[39;49mfit(show_fig\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/dev/my-doc2vec/analyst.py:49\u001b[0m, in \u001b[0;36mAnalyst.fit\u001b[0;34m(self, on_epoch_start, show_fig)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m     47\u001b[0m     \u001b[39mself\u001b[39m, on_epoch_start: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, show_fig: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     48\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     loss_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mfit(on_epoch_start\u001b[39m=\u001b[39;49mon_epoch_start)\n\u001b[1;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m show_fig:\n\u001b[1;32m     51\u001b[0m         visualize_loss(loss_dict)\n",
      "File \u001b[0;32m~/dev/my-doc2vec/trainers.py:265\u001b[0m, in \u001b[0;36mPyTorchTrainer.fit\u001b[0;34m(self, on_epoch_start)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm\u001b[39m.\u001b[39mtqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_data_loader)):\n\u001b[1;32m    256\u001b[0m     (\n\u001b[1;32m    257\u001b[0m         seq_index,\n\u001b[1;32m    258\u001b[0m         item_indicies,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m         target_index,\n\u001b[1;32m    263\u001b[0m     ) \u001b[39m=\u001b[39m data\n\u001b[0;32m--> 265\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward(\n\u001b[1;32m    266\u001b[0m         seq_index\u001b[39m=\u001b[39;49mseq_index,\n\u001b[1;32m    267\u001b[0m         item_indicies\u001b[39m=\u001b[39;49mitem_indicies,\n\u001b[1;32m    268\u001b[0m         seq_meta_indicies\u001b[39m=\u001b[39;49mseq_meta_indicies,\n\u001b[1;32m    269\u001b[0m         item_meta_indicies\u001b[39m=\u001b[39;49mitem_meta_indicies,\n\u001b[1;32m    270\u001b[0m         item_meta_weights\u001b[39m=\u001b[39;49mitem_meta_weights,\n\u001b[1;32m    271\u001b[0m         target_index\u001b[39m=\u001b[39;49mtarget_index,\n\u001b[1;32m    272\u001b[0m     )\n\u001b[1;32m    273\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    274\u001b[0m     loss\u001b[39m.\u001b[39mbackward()  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/my-doc2vec/model.py:59\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, seq_index, item_indicies, seq_meta_indicies, item_meta_indicies, item_meta_weights, target_index)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     22\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     23\u001b[0m     seq_index: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     target_index: Tensor,\n\u001b[1;32m     29\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     30\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m    モデルに入力を与えた時の損失\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m        loss: Tensor\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     pos_out, pos_label, neg_out, neg_label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalc_out(\n\u001b[1;32m     60\u001b[0m         seq_index\u001b[39m=\u001b[39;49mseq_index,\n\u001b[1;32m     61\u001b[0m         item_indicies\u001b[39m=\u001b[39;49mitem_indicies,\n\u001b[1;32m     62\u001b[0m         seq_meta_indicies\u001b[39m=\u001b[39;49mseq_meta_indicies,\n\u001b[1;32m     63\u001b[0m         item_meta_indicies\u001b[39m=\u001b[39;49mitem_meta_indicies,\n\u001b[1;32m     64\u001b[0m         item_meta_weights\u001b[39m=\u001b[39;49mitem_meta_weights,\n\u001b[1;32m     65\u001b[0m         target_index\u001b[39m=\u001b[39;49mtarget_index,\n\u001b[1;32m     66\u001b[0m     )\n\u001b[1;32m     67\u001b[0m     loss_pos \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mbinary_cross_entropy(pos_out, pos_label)\n\u001b[1;32m     68\u001b[0m     loss_neg \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mbinary_cross_entropy(neg_out, neg_label)\n",
      "File \u001b[0;32m~/dev/my-doc2vec/model.py:276\u001b[0m, in \u001b[0;36mAttentiveModel2.calc_out\u001b[0;34m(self, seq_index, item_indicies, seq_meta_indicies, item_meta_indicies, item_meta_weights, target_index)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalc_out\u001b[39m(\n\u001b[1;32m    268\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    269\u001b[0m     seq_index: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m     target_index: Tensor,\n\u001b[1;32m    275\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor, Tensor, Tensor]:\n\u001b[0;32m--> 276\u001b[0m     c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalc_context_vector(\n\u001b[1;32m    277\u001b[0m         seq_index\u001b[39m=\u001b[39;49mseq_index,\n\u001b[1;32m    278\u001b[0m         item_indicies\u001b[39m=\u001b[39;49mitem_indicies,\n\u001b[1;32m    279\u001b[0m         seq_meta_indicies\u001b[39m=\u001b[39;49mseq_meta_indicies,\n\u001b[1;32m    280\u001b[0m         item_meta_indicies\u001b[39m=\u001b[39;49mitem_meta_indicies,\n\u001b[1;32m    281\u001b[0m         item_meta_weights\u001b[39m=\u001b[39;49mitem_meta_weights,\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\u001b[39m.\u001b[39mforward(c, target_index)\n",
      "File \u001b[0;32m~/dev/my-doc2vec/model.py:305\u001b[0m, in \u001b[0;36mAttentiveModel2.calc_context_vector\u001b[0;34m(self, seq_index, item_indicies, seq_meta_indicies, item_meta_indicies, item_meta_weights)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39m# add meta embedding\u001b[39;00m\n\u001b[1;32m    304\u001b[0m h_item_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_item_meta\u001b[39m.\u001b[39mforward(item_meta_indicies)\n\u001b[0;32m--> 305\u001b[0m h_item_meta_weighted \u001b[39m=\u001b[39m calc_weighted_meta(h_item_meta, item_meta_weights)\n\u001b[1;32m    306\u001b[0m h_items \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m h_item_meta_weighted\n\u001b[1;32m    307\u001b[0m \u001b[39m# take mean\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/my-doc2vec/layer.py:27\u001b[0m, in \u001b[0;36mcalc_weighted_meta\u001b[0;34m(h_meta, meta_weights)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalc_weighted_meta\u001b[39m(h_meta: Tensor, meta_weights: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmatmul(\n\u001b[1;32m     28\u001b[0m         h_meta\u001b[39m.\u001b[39;49mmT,\n\u001b[1;32m     29\u001b[0m         meta_weights\u001b[39m.\u001b[39;49mview((\u001b[39m*\u001b[39;49mh_meta\u001b[39m.\u001b[39;49mshape[:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m)),\n\u001b[1;32m     30\u001b[0m     )\u001b[39m.\u001b[39msqueeze()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "analyst.fit(show_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('3.10.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a5fb540920344d2a30df49d123c0d51f1e8fc17e24494fc3a54f6f29186e4c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
